# ArtQuest Evaluation Configuration for BLIP2 with KV Modulation
# 
# This config follows the structure of VQAv2 evaluation configs.
# Set data_percentage to 1.0 to use the full dataset, or 0.5 to use 50% of the data, etc.

# Model configuration: use the KV modulation backend
model: "blip2_kv"

# Model-specific configuration for KV modulation
model_config:
  # Path to the trained KV-modulated checkpoint
  checkpoint: "/home/linux/artcap-blip2-4/models/KV/outputs/best_checkpoint.pt"

  # Optional shortcut: if provided here, it will be forwarded into the
  # internal model config passed to the loader utility.
  efficientnet_checkpoint: "/home/linux/artcap-blip2-4/runs/efficientnet-28/best.pt"

  # Specify local OPT model to avoid downloading
  opt_model: "/data/huggingface/hub/models--facebook--opt-2.7b"

  kv_modulation:
    enabled: true
    num_prefix_tokens: 8

  architecture:
    vit_model: "eva_clip_g"
    img_size: 224
    num_query_token: 32
    max_txt_len: 32
    freeze_vit: true
    freeze_llm: true
    freeze_efficientnet: true

# Data paths (relative to project root)
data:
  artquest_test: "artquest/data/artquest/artquest_test.csv"
  semart_cache: "artquest/data/semart_cache.csv"
  retrieved_candidates: "artquest/retrieval_module/output/SEMARTCLIP.200BS.IMAGE_TO_TEXT_reference_candidate.pickle"
  image_root: "artquest/data/SemArt/Images"  # Root directory for ArtQuest images

run:
  # optimization-specific
  batch_size_eval: 1  # Process one at a time for ArtQuest
  
  # inference-specific (for BLIP2)
  # max_len: 控制生成答案的最大token数（不包括输入prompt的token）
  #   - VQAv2短答案: 推荐 10-15
  #   - ArtQuest答案: 推荐 20-30（因为答案可能包含完整句子）
  #   注意：token数通常比单词数多（因为标点、词干化等），建议设置稍大一些
  max_len: 80  # Allow longer completions to avoid truncated answers in descriptive responses
  
  # min_len: 生成答案的最小token数
  #   - 通常设置为1，允许单字/单词答案
  min_len: 1
  
  # num_beams: Beam search的beam数量
  #   - 更大的值（5-10）通常产生更好的答案，但速度更慢
  #   - 推荐值：5（平衡质量和速度）
  num_beams: 5
  
  inference_method: "generate"
  prompt: "{}"  # BLIP2 KV prompt expects a single slot; adapter fills question + context
  
  seed: 2
  output_dir: "ArtQuest/output/KV"
  
  # Set to 1.0 to use full dataset, 0.5 to use 50%, etc.
  data_percentage: 0.1
  
  # distribution-specific
  device: "cuda"
