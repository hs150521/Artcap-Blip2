# ArtQuest Evaluation Configuration for BLIP2
# 
# This config follows the structure of VQAv2 evaluation configs.
# Set data_percentage to 1.0 to use the full dataset, or 0.5 to use 50% of the data, etc.

# Model configuration: use a string identifier to select the model backend
# Supported values:
#   - "blip2": Standard BLIP2 model via LAVIS (default)
#   - "blip2_prompt_aug": BLIP2 with EfficientNet-based prompt augmentation
#   - "blip2_kv": BLIP2 with KV modulation
#   - "blip2_gated": BLIP2 with Gated modulation
model: "blip2"

# Optional: Model-specific configuration
# For backward compatibility with old config format, if model is set to "blip2",
# you can still specify LAVIS-specific options:
# model:
#   arch: blip2_opt
#   model_type: pretrain_opt2.7b
#   use_grad_checkpoint: False

# Data paths (relative to project root)
data:
  artquest_test: "artquest/data/artquest/artquest_test.csv"
  semart_cache: "artquest/data/semart_cache.csv"
  retrieved_candidates: "artquest/retrieval_module/output/SEMARTCLIP.200BS.IMAGE_TO_TEXT_reference_candidate.pickle"
  image_root: "artquest/data/SemArt/Images"  # Root directory for ArtQuest images

run:
  # optimization-specific
  batch_size_eval: 1  # Process one at a time for ArtQuest
  
  # inference-specific (for BLIP2)
  # max_len: 控制生成答案的最大token数（不包括输入prompt的token）
  #   - VQAv2短答案: 推荐 10-15
  #   - ArtQuest答案: 推荐 20-30（因为答案可能包含完整句子）
  #   注意：token数通常比单词数多（因为标点、词干化等），建议设置稍大一些
  max_len: 80  # Allow longer completions to avoid mid-word truncation on descriptive answers
  
  # min_len: 生成答案的最小token数
  #   - 通常设置为1，允许单字/单词答案
  min_len: 1
  
  # num_beams: Beam search的beam数量
  #   - 更大的值（5-10）通常产生更好的答案，但速度更慢
  #   - 推荐值：5（平衡质量和速度）
  num_beams: 5
  
  inference_method: "generate"
  prompt: "Question: {question}\nContext: {context}\nShort answer:"
  
  seed: 2
  output_dir: "ArtQuest/output/BLIP2"
  
  # Set to 1.0 to use full dataset, 0.5 to use 50%, etc.
  data_percentage: 0.1
  
  # distribution-specific
  device: "cuda"
