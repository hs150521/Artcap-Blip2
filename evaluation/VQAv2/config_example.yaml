# Copyright (c) 2022, salesforce.com, inc.
# All rights reserved.
# SPDX-License-Identifier: BSD-3-Clause
# For full license text, see the LICENSE file in the repo root or https://opensource.org/licenses/BSD-3-Clause

# Overall Accuracy is: 51.88 (result different from BLIP-2 paper due to different implementation and transformers version)
# 
# This config is based on vqav2_zeroshot_opt_eval.yaml with added data_percentage option.
# Set data_percentage to 1.0 to use the full dataset, or 0.5 to use 50% of the data, etc.

# Model configuration: use a string identifier to select the model backend
# Supported values:
#   - "blip2": Standard BLIP2 model via LAVIS (default)
#   - "blip2_prompt_aug": BLIP2 with EfficientNet-based prompt augmentation
model: "blip2"

# Optional: Model-specific configuration
# For blip2_prompt_aug, you can configure:
# model_config:
#   efficientnet:
#     topk: 3  # Number of top EfficientNet labels to include
#     prompt_template: "Image context hints: {labels}. "  # Template for label injection
#   max_new_tokens: 40  # Maximum tokens to generate
#   temperature: 0.0  # Sampling temperature (0.0 for greedy)

# For backward compatibility with old config format, if model is set to "blip2",
# you can still specify LAVIS-specific options:
# model:
#   arch: blip2_opt
#   model_type: pretrain_opt2.7b
#   use_grad_checkpoint: False

datasets:
  coco_vqa: # name of the dataset builder
    type: eval
    vis_processor:
        eval:
          name: "blip_image_eval"
          image_size: 224
    text_processor:
        eval:
          name: "blip_question"
    build_info:
        images:
            storage: '/data/lavis/coco/images/'

run:
  task: vqa
  # optimization-specific
  batch_size_train: 16
  batch_size_eval: 64
  num_workers: 6

  # inference-specific
  max_len: 10
  min_len: 1
  num_beams: 5
  inference_method: "generate"
  prompt: "Question: {} Short answer:"

  seed: 42
  output_dir: "output/BLIP2/VQA"

  evaluate: True
  test_splits: ["val"]
  
  # Set to 1.0 to use full dataset, 0.5 to use 50%, etc.
  data_percentage: 0.1

  # distribution-specific
  device: "cuda"
  world_size: 1
  dist_url: "env://"
  distributed: True
