# Configuration for evaluating KV-modulated BLIP2 on VQAv2.
#
# This config uses the best checkpoint from /data/artcap-blip2-4/models/KV/runs/best.pt

model: "blip2_kv"

model_config:
  # Path to the trained KV-modulated checkpoint
  checkpoint: "/data/artcap-blip2-4/models/KV/runs/best.pt"

  # EfficientNet checkpoint path (required for KV modulation)
  efficientnet_checkpoint: "/data/artcap-blip2-4/models/efficientnet-28/runs/best.pt"

  # Model configuration
  model:
    opt_model: "facebook/opt-2.7b"
    efficientnet_output_dim: 768
    enable_efficientnet_grad: false
    prompt_mapper:
      hidden_dim: 1024
      num_tokens: 4
      dropout: 0.1
      use_layer_norm: true

  # KV modulation configuration
  kv_modulation:
    controller_dim: 768
    hidden_dim: 768
    init_scale: 0.01
    use_layer_norm: true

  # Architecture configuration
  architecture:
    vit_model: "eva_clip_g"
    img_size: 224
    num_query_token: 32
    max_txt_len: 32
    freeze_vit: true
    freeze_llm: true
    freeze_efficientnet: true

datasets:
  coco_vqa:
    type: eval
    vis_processor:
      eval:
        name: "blip_image_eval"
        image_size: 224
    text_processor:
      eval:
        name: "blip_question"
    build_info:
      images:
        storage: "/data/artcap-blip2-4/datasets/coco/images/"

run:
  task: vqa

  batch_size_train: 4
  batch_size_eval: 8
  num_workers: 4

  max_len: 10
  min_len: 1
  num_beams: 5
  inference_method: "generate"
  prompt: "Question: {} Short answer:"
  length_penalty: 0.0

  seed: 42
  output_dir: "output/KV/VQA"

  evaluate: true
  test_splits: ["val"]
  data_percentage: 0.01

  device: "cuda"
  world_size: 1
  dist_url: "env://"
  distributed: true

